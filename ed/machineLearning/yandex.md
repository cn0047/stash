Machine Learning
-

[source](http://habrahabr.ru/company/yandex/blog/208034/)
|
https://www.kaggle.com/
|
http://tunedit.org/

1.

* Метод наименьших квадратов, закон Гука.
* Matloab, pyton.
* 3 вида задач:
    * регрессия (стоимость квартиры от метро, этажа, цента и т.д.),
    * классификация (давать кредит или нет первому попавшемуся),
    * ранжирование (ядекс серч),
* Предикат - функция от объекта.

2.

* Метрические алгоритмы классификации.
* Отбор объектов (ближайший сосед, весомые соседи, отбор эталонов...).
* Профиль компактности (граница между классами...).

3.

* Логические алгоритмы классификации.
* Покрывающий набор конъюнкций.
* Связанные списки!
* Бинарное дерево (Decision tree) - жадный алгоритм с переобучением...
* Выборку нужно делить на 3 части, из них 2/3 - на обучение, 1/3 - на контроль.

4.

* Линейные методы классификации.
* Метод стохастического градиента.
* Вектор классификации.

5.

* Метод опорных векторов (SVM, support vector machine).
* Недостатки svm:
    * опорными объектами могут быть шумовые объекты,
    * непонятно как выбирать ядро,
    * есть отбор опорных объектов, но нет отбора признаков.
* RVM - берет сильно меньше опорных объектов чем svm.
* LASSO (Least Absolute Shrinkage And Selection) SVM.
* Elastic Net SVM.
* SFM (Support Features Machine).
* RFM (Relevance Features Machine).

6.

* Линейная модель регрессии.
* Метод главных компонент - обучение без учителя.
* Гребневая регрессия.

7.

* Нелинеинная регрессия.
* IRLS (Iteratively Reweighted Least Squares).
* Backfitting.
* LOWESS (LOcally WEighted Scatter plot Smoothing)

8.

* Адаптивные методы краткосрочного прогнозирования.
* Временные ряды.
* Адаптивная селективная модель.
* Адаптивная композиция моделей.

9.

* Байесовская теория классификации.
* Оптимальный байесовский классификатор.
* Метод парзеновского окна.

10.

https://www.youtube.com/watch?v=4CPVlMWQtk8&index=10&list=PLJOzdkh8T5kp99tGTEFjH_b9zqEQiiBtC
