Machine Learning
-

[source](http://habrahabr.ru/company/yandex/blog/208034/)
|
https://www.kaggle.com/
|
http://tunedit.org/

1.

* Метод наименьших квадратов, закон Гука.
* Matloab, pyton.
* Виды задач:
    * регрессия (стоимость квартиры от метро, этажа, цента и т.д.),
    * классификация (давать кредит или нет первому попавшемуся),
    * ранжирование (ядекс серч),
    * прогнозирование,
    * кластеризация.
* Предикат - функция от объекта.

2.

* Метрические алгоритмы классификации.
* Отбор объектов (ближайший сосед, весомые соседи, отбор эталонов...).
* Профиль компактности (граница между классами...).

3.

* Логические алгоритмы классификации.
* Покрывающий набор конъюнкций.
* Связанные списки!
* Бинарное дерево (Decision tree) - жадный алгоритм с переобучением...
* Выборку нужно делить на 3 части, из них 2/3 - на обучение, 1/3 - на контроль.

4.

* Линейные методы классификации.
* Метод стохастического градиента (stochastic gradient).
* Вектор классификации (разделяющая поверхность).
* Стохастический EM-алгоритм.

5.

* Метод опорных векторов (SVM, support vector machine).
* Недостатки svm:
    * опорными объектами могут быть шумовые объекты,
    * непонятно как выбирать ядро,
    * есть отбор опорных объектов, но нет отбора признаков.
* RVM - берет сильно меньше опорных объектов чем svm.
* LASSO (Least Absolute Shrinkage And Selection) SVM.
* Elastic Net SVM.
* SFM (Support Features Machine).
* RFM (Relevance Features Machine).

6.

* Линейная модель регрессии.
* Метод главных компонент - обучение без учителя (не классификация и не регрессия).
* Гребневая регрессия.

7.

* Нелинеинная регрессия.
* IRLS (Iteratively Reweighted Least Squares).
* Backfitting.
* LOWESS (LOcally WEighted Scatter plot Smoothing)

8.

* Адаптивные методы краткосрочного прогнозирования.
* Временные ряды.
* Адаптивная селективная модель.
* Адаптивная композиция моделей.

9.

* Байесовская теория классификации.
* Оптимальный байесовский классификатор.
* Метод парзеновского окна.

10.

* Линейный дискриминант Фишера.
* Ковариационная матрица.

11.

* Логическая регрессия!
* Скоринговая карта.
* ЕМ-алгоритм.
* Radial Bassis Functions.

12.

* Поиск ассоциативных правил.
* Алгоритм APriory.
* Префиксное дерево (FP, frequent pattern).

13.

* Алгоритм полного перебора (Full Search).
* Алгоритм жадного добавления (Add).
* Алгоритм поочередного добавления и удаления (Add-Del).
* Поиск в глубину.
* Поиск в ширину.
* Генетический алгоритм поиска.

14.

* Нейронная сеть (двухслойная, трёхслойная).
* Динамически обучающийся поток.
* Оптимальная порча мозга (OBD, optimal brain damage).

15.

* Алгоритм AdaBoost.
* Алгоритм Gradient Boosting.
* Алгоритм ComBoost.

16.

* Random Forest.
* В задачах классификации нужно строить дерево в лист которого будет доходить только 1 объект!
* В регрессии - 5 объектов на лист!

17.

* Метод обучения uncertainly sampling.
* Усредненная дивергенция Кульбака-Лейблера.
* Метод обучения expected model change.
* Query By Committee.
* Expected Error Reduction.
* Variance Reduction.
* Уменьшение дисперсии.

18.

https://www.youtube.com/watch?v=EioJ902VCmk&index=18&list=PLJOzdkh8T5kp99tGTEFjH_b9zqEQiiBtC
